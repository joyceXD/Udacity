}
}
for(i in 1:noOfIter)
{
removed_ind = c(1,2,18,20)#q30a14
data_train_sm = SMOTE(churn ~ ., data_train, perc.over = 300,perc.under=134)
dt_model <- rpart(churn ~ ., data = data_train_sm[,-removed_ind],
method = "class", parms = list(split="information"),
control = rpart.control(maxdepth = 5, cp = 0.01, xval=5))
pred = predict(dt_model, newdata = data_test, type = "class")
#fancyRpartPlot(dt_model, main = paste("Denoised and SMOTED:", i))
cm = confusionMatrix(pred, data_test$churn, positive = "1")
cm
sen = cm$byClass["Sensitivity"]
spe = cm$byClass["Specificity"]
accuracy_dnsm = 2*sen*spe/(sen + spe)
accuracy_dnsm
print(paste("Iteration: ", i))
if(accuracy_dnsm >= prev_accuracy)
{
dt_model_sel = dt_model
prev_accuracy = accuracy_dnsm
print(accuracy_dnsm)
trainData = data_train_sm
fancyRpartPlot(dt_model_sel,main = paste("Sen=",round(sen,3),": Spe=", round(spe,3), " :Score=", round(prev_accuracy, 3)))
#modelList[j]=dt_model
#fancyRpartPlot(dt_model, main = paste("Acc:",accuracy_dnsm))
#j = j+1
}
}
noOfIter = 1000
modelList <- as.list(x = "rpart")
dt_model_sel <- c()
prev_accuracy = 0.50
j = 0
trainData <- data.frame()
for(i in 1:noOfIter)
{
removed_ind = c(1,2,18,20)#q30a14
data_train_sm = SMOTE(churn ~ ., data_train, perc.over = 300,perc.under=134)
dt_model <- rpart(churn ~ ., data = data_train_sm[,-removed_ind],
method = "class", parms = list(split="information"),
control = rpart.control(maxdepth = 5, cp = 0.01, xval=5))
pred = predict(dt_model, newdata = data_test, type = "class")
#fancyRpartPlot(dt_model, main = paste("Denoised and SMOTED:", i))
cm = confusionMatrix(pred, data_test$churn, positive = "1")
cm
sen = cm$byClass["Sensitivity"]
spe = cm$byClass["Specificity"]
accuracy_dnsm = 2*sen*spe/(sen + spe)
accuracy_dnsm
print(paste("Iteration: ", i))
if(accuracy_dnsm >= prev_accuracy)
{
dt_model_sel = dt_model
prev_accuracy = accuracy_dnsm
print(accuracy_dnsm)
trainData = data_train_sm
fancyRpartPlot(dt_model_sel,main = paste("Sen=",round(sen,3),": Spe=", round(spe,3), " :Score=", round(prev_accuracy, 3)))
#modelList[j]=dt_model
#fancyRpartPlot(dt_model, main = paste("Acc:",accuracy_dnsm))
#j = j+1
}
}
noOfIter = 1000
modelList <- as.list(x = "rpart")
dt_model_sel <- c()
prev_accuracy = 0.50
j = 0
trainData <- data.frame()
for(i in 1:noOfIter)
{
removed_ind = c(1,2,18,20)#q30a14
data_train_sm = SMOTE(churn ~ ., data_train, perc.over = 300,perc.under=134)
dt_model <- rpart(churn ~ ., data = data_train_sm[,-removed_ind],
method = "class", parms = list(split="information"),
control = rpart.control(maxdepth = 5, cp = 0.01, xval=5))
pred = predict(dt_model, newdata = data_test, type = "class")
#fancyRpartPlot(dt_model, main = paste("Denoised and SMOTED:", i))
cm = confusionMatrix(pred, data_test$churn, positive = "1")
cm
sen = cm$byClass["Sensitivity"]
spe = cm$byClass["Specificity"]
accuracy_dnsm = 2*sen*spe/(sen + spe)
accuracy_dnsm
print(paste("Iteration: ", i))
if(accuracy_dnsm >= prev_accuracy)
{
dt_model_sel = dt_model
prev_accuracy = accuracy_dnsm
print(accuracy_dnsm)
trainData = data_train_sm
fancyRpartPlot(dt_model_sel,main = paste("Sen=",round(sen,3),": Spe=", round(spe,3), " :Score=", round(prev_accuracy, 3)))
#modelList[j]=dt_model
#fancyRpartPlot(dt_model, main = paste("Acc:",accuracy_dnsm))
#j = j+1
}
}
noOfIter = 1000
modelList <- as.list(x = "rpart")
dt_model_sel <- c()
prev_accuracy = 0.50
j = 0
trainData <- data.frame()
for(i in 1:noOfIter)
{
removed_ind = c(1,2,18,20)#q30a14
data_train_sm = SMOTE(churn ~ ., data_train, perc.over = 300,perc.under=134)
dt_model <- rpart(churn ~ ., data = data_train_sm[,-removed_ind],
method = "class", parms = list(split="information"),
control = rpart.control(maxdepth = 5, cp = 0.01, xval=5))
pred = predict(dt_model, newdata = data_test, type = "class")
#fancyRpartPlot(dt_model, main = paste("Denoised and SMOTED:", i))
cm = confusionMatrix(pred, data_test$churn, positive = "1")
cm
sen = cm$byClass["Sensitivity"]
spe = cm$byClass["Specificity"]
accuracy_dnsm = 2*sen*spe/(sen + spe)
accuracy_dnsm
print(paste("Iteration: ", i))
if(accuracy_dnsm >= prev_accuracy)
{
dt_model_sel = dt_model
prev_accuracy = accuracy_dnsm
print(accuracy_dnsm)
trainData = data_train_sm
fancyRpartPlot(dt_model_sel,main = paste("Sen=",round(sen,3),": Spe=", round(spe,3), " :Score=", round(prev_accuracy, 3)))
#modelList[j]=dt_model
#fancyRpartPlot(dt_model, main = paste("Acc:",accuracy_dnsm))
#j = j+1
}
}
noOfIter = 1000
modelList <- as.list(x = "rpart")
dt_model_sel <- c()
prev_accuracy = 0.50
j = 0
trainData <- data.frame()
for(i in 1:noOfIter)
{
removed_ind = c(1,2,18,20)#q30a14
data_train_sm = SMOTE(churn ~ ., data_train, perc.over = 300,perc.under=134)
dt_model <- rpart(churn ~ ., data = data_train_sm[,-removed_ind],
method = "class", parms = list(split="information"),
control = rpart.control(maxdepth = 5, cp = 0.01, xval=5))
pred = predict(dt_model, newdata = data_test, type = "class")
#fancyRpartPlot(dt_model, main = paste("Denoised and SMOTED:", i))
cm = confusionMatrix(pred, data_test$churn, positive = "1")
cm
sen = cm$byClass["Sensitivity"]
spe = cm$byClass["Specificity"]
accuracy_dnsm = 2*sen*spe/(sen + spe)
accuracy_dnsm
print(paste("Iteration: ", i))
if(accuracy_dnsm >= prev_accuracy)
{
dt_model_sel = dt_model
prev_accuracy = accuracy_dnsm
print(accuracy_dnsm)
trainData = data_train_sm
fancyRpartPlot(dt_model_sel,main = paste("Sen=",round(sen,3),": Spe=", round(spe,3), " :Score=", round(prev_accuracy, 3)))
#modelList[j]=dt_model
#fancyRpartPlot(dt_model, main = paste("Acc:",accuracy_dnsm))
#j = j+1
}
}
library(caret)
library(FSelector)
library(mlbench)
library(rattle)
library(rpart)
library(rpart.plot)
library(ROCR)
library(DMwR)
library(NoiseFiltersR)
set.seed(1234)
data <- read.csv("C:/Project/ChurnPrediction/development/data/data_train_sm_model4.csv", header = T)
data$churn[which(data$churn == 2)] <- 1
data$churn <- as.factor(data$churn)
# split data to training and test
x = nearZeroVar(data, saveMetrics = T)
varFeatures = row.names(x[x$zeroVar == "FALSE",])
data = data[,varFeatures]
data = data[,-c(1,2,25)]
train <- createDataPartition(data$churn, p=0.8, list = F)
data_train = data[train,]
data_test = data[-train,]
data_train = (NoiseFiltersR::C45robustFilter(churn~., data_train))$cleanData
View(data)
library(caret)
library(FSelector)
library(mlbench)
library(rattle)
library(rpart)
library(rpart.plot)
library(ROCR)
library(DMwR)
library(NoiseFiltersR)
set.seed(1234)
data <- read.csv("C:/Project/ChurnPrediction/development/data/data_train_sm_model4.csv", header = T)
data$churn[which(data$churn == 2)] <- 1
data$churn <- as.factor(data$churn)
# split data to training and test
x = nearZeroVar(data, saveMetrics = T)
varFeatures = row.names(x[x$zeroVar == "FALSE",])
data = data[,varFeatures]
# data = data[,-c(1,2,25)]
train <- createDataPartition(data$churn, p=0.8, list = F)
data_train = data[train,]
data_test = data[-train,]
data_train = (NoiseFiltersR::C45robustFilter(churn~., data_train))$cleanData
View(data)
noOfIter = 1000
modelList <- as.list(x = "rpart")
dt_model_sel <- c()
prev_accuracy = 0.50
j = 0
trainData <- data.frame()
for(i in 1:noOfIter)
{
removed_ind = c(1,2,18,20)#q30a14
data_train_sm = SMOTE(churn ~ ., data_train, perc.over = 300,perc.under=134)
dt_model <- rpart(churn ~ ., data = data_train_sm[,-removed_ind],
method = "class", parms = list(split="information"),
control = rpart.control(maxdepth = 5, cp = 0.01, xval=5))
pred = predict(dt_model, newdata = data_test, type = "class")
#fancyRpartPlot(dt_model, main = paste("Denoised and SMOTED:", i))
cm = confusionMatrix(pred, data_test$churn, positive = "1")
cm
sen = cm$byClass["Sensitivity"]
spe = cm$byClass["Specificity"]
accuracy_dnsm = 2*sen*spe/(sen + spe)
accuracy_dnsm
print(paste("Iteration: ", i))
if(accuracy_dnsm >= prev_accuracy)
{
dt_model_sel = dt_model
prev_accuracy = accuracy_dnsm
print(accuracy_dnsm)
trainData = data_train_sm
fancyRpartPlot(dt_model_sel,main = paste("Sen=",round(sen,3),": Spe=", round(spe,3), " :Score=", round(prev_accuracy, 3)))
#modelList[j]=dt_model
#fancyRpartPlot(dt_model, main = paste("Acc:",accuracy_dnsm))
#j = j+1
}
}
noOfIter = 1000
modelList <- as.list(x = "rpart")
dt_model_sel <- c()
prev_accuracy = 0.50
j = 0
trainData <- data.frame()
for(i in 1:noOfIter)
{
removed_ind = c(1,2,18,20)#q30a14
data_train_sm = SMOTE(churn ~ ., data_train, perc.over = 300,perc.under=134)
dt_model <- rpart(churn ~ ., data = data_train_sm[,-removed_ind],
method = "class", parms = list(split="information"),
control = rpart.control(maxdepth = 5, cp = 0.01, xval=5))
pred = predict(dt_model, newdata = data_test, type = "class")
#fancyRpartPlot(dt_model, main = paste("Denoised and SMOTED:", i))
cm = confusionMatrix(pred, data_test$churn, positive = "1")
cm
sen = cm$byClass["Sensitivity"]
spe = cm$byClass["Specificity"]
accuracy_dnsm = 2*sen*spe/(sen + spe)
accuracy_dnsm
print(paste("Iteration: ", i))
if(accuracy_dnsm >= prev_accuracy)
{
dt_model_sel = dt_model
prev_accuracy = accuracy_dnsm
print(accuracy_dnsm)
trainData = data_train_sm
fancyRpartPlot(dt_model_sel,main = paste("Sen=",round(sen,3),": Spe=", round(spe,3), " :Score=", round(prev_accuracy, 3)))
#modelList[j]=dt_model
#fancyRpartPlot(dt_model, main = paste("Acc:",accuracy_dnsm))
#j = j+1
}
}
noOfIter = 1000
modelList <- as.list(x = "rpart")
dt_model_sel <- c()
prev_accuracy = 0.50
j = 0
trainData <- data.frame()
for(i in 1:noOfIter)
{
removed_ind = c(1,2,18,20)#q30a14
data_train_sm = SMOTE(churn ~ ., data_train, perc.over = 300,perc.under=134)
dt_model <- rpart(churn ~ ., data = data_train_sm[,-removed_ind],
method = "class", parms = list(split="information"),
control = rpart.control(maxdepth = 5, cp = 0.01, xval=5))
pred = predict(dt_model, newdata = data_test, type = "class")
#fancyRpartPlot(dt_model, main = paste("Denoised and SMOTED:", i))
cm = confusionMatrix(pred, data_test$churn, positive = "1")
cm
sen = cm$byClass["Sensitivity"]
spe = cm$byClass["Specificity"]
accuracy_dnsm = 2*sen*spe/(sen + spe)
accuracy_dnsm
print(paste("Iteration: ", i))
if(accuracy_dnsm >= prev_accuracy)
{
dt_model_sel = dt_model
prev_accuracy = accuracy_dnsm
print(accuracy_dnsm)
trainData = data_train_sm
fancyRpartPlot(dt_model_sel,main = paste("Sen=",round(sen,3),": Spe=", round(spe,3), " :Score=", round(prev_accuracy, 3)))
#modelList[j]=dt_model
#fancyRpartPlot(dt_model, main = paste("Acc:",accuracy_dnsm))
#j = j+1
}
}
set.seed(1234)
noOfIter = 1000
modelList <- as.list(x = "rpart")
dt_model_sel <- c()
prev_accuracy = 0.50
j = 0
trainData <- data.frame()
for(i in 1:noOfIter)
{
removed_ind = c(1,2,18,20)#q30a14
data_train_sm = SMOTE(churn ~ ., data_train, perc.over = 300,perc.under=134)
dt_model <- rpart(churn ~ ., data = data_train_sm[,-removed_ind],
method = "class", parms = list(split="information"),
control = rpart.control(maxdepth = 5, cp = 0.01, xval=5))
pred = predict(dt_model, newdata = data_test, type = "class")
#fancyRpartPlot(dt_model, main = paste("Denoised and SMOTED:", i))
cm = confusionMatrix(pred, data_test$churn, positive = "1")
cm
sen = cm$byClass["Sensitivity"]
spe = cm$byClass["Specificity"]
accuracy_dnsm = 2*sen*spe/(sen + spe)
accuracy_dnsm
print(paste("Iteration: ", i))
if(accuracy_dnsm >= prev_accuracy)
{
dt_model_sel = dt_model
prev_accuracy = accuracy_dnsm
print(accuracy_dnsm)
trainData = data_train_sm
fancyRpartPlot(dt_model_sel,main = paste("Sen=",round(sen,3),": Spe=", round(spe,3), " :Score=", round(prev_accuracy, 3)))
#modelList[j]=dt_model
#fancyRpartPlot(dt_model, main = paste("Acc:",accuracy_dnsm))
#j = j+1
}
}
load("C:/Project/ChurnPrediction/development/ig data/DT_Model.Rdata")
fancyRpartPlot(dt_model)
library(caret)
library(FSelector)
library(mlbench)
library(rattle)
library(rpart)
library(rpart.plot)
library(ROCR)
library(DMwR)
library(NoiseFiltersR)
fancyRpartPlot(dt_model_sel) # final model
fancyRpartPlot(dt_model)
summary(dt_model)
load(stagec)
data("stagec")
progstat <- factor(stagec$pgstat, levels = 0:1, labels = c("No", "Prog"))
cfit <- rpart(progstat ~ age + eet + g2 + grade + gleason + ploidy,
data = stagec, method = 'class')
View(stagec)
table(stagec$ploidy)
summary(cfit)
fancyRpartPlot(stagec)
fancyRpartPlot(cfit)
View(stagec)
table(stagec$pgstat)
summary(stagec)
cut(grade, c(0, 2.5, 4)
)
with(stagec, cut(grade, c(0, 2.5, 4)))
temp <- with(stagec, table(cut(grade, c(0, 2.5, 4)),
cut(gleason, c(2, 5.5, 10)),
exclude = NULL))
temp
table(with(stagec, cut(grade, c(0, 2.5, 4))))
(1/3)*log2
(1/3)*log2(1/3) + (2/3)*log2(2/3)
information.gain
View(stagec)
library(ggplot2)
data("diamonds")
ggplot(data = diamonds, mapping = aes(x = x, y = price)) +
geom_point()
View(diamonds)
ggplot(data = diamonds, mapping = aes(x = x, y = price)) +
geom_point() +
labs(title = "Diamond data: price vs. x", x = "x", y = "price")
cov(diamonds$x, diamonds$price)
cov(diamonds$y, diamonds$price)
cov(diamonds$z, diamonds$price)
cor(diamonds$x, diamonds$price)
cor(diamonds$y, diamonds$price)
cor(diamonds$z, diamonds$price)
ggplot(data = diamonds, mapping = aes(x = price, y = depth)) +
geom_point() +
ggtitle("Diamonds data: price vs. depth") +
xlab("price") +
ylab("depth")
ggplot(data = diamonds, mapping = aes(x = depth, y = price)) +
geom_point() +
ggtitle("Diamonds data: price vs. depth") +
xlab("depth") +
ylab("price")
ggplot(data = diamonds, mapping = aes(x = price, y = depth)) +
geom_point(alpha = 1/100) +
scale_x_continuous(breaks = 2)
ggplot(data = diamonds, mapping = aes(x = depth, y = price)) +
geom_point(alpha = 1/100) +
scale_x_continuous(breaks = 2)
ggplot(data = diamonds, mapping = aes(x = depth, y = price)) +
geom_point(alpha = 1/100) +
scale_x_continuous(breaks = seq(0, 100, by = 2))
cor(diamonds$depth, diamonds$price)
df <- diamonds[diamonds$price < quantile(diamonds$price, 0.01) &&
diamonds$carat < quantile(diamonds$carat, 0.01)]
df <- diamonds[(diamonds$price < quantile(diamonds$price, 0.99) &&
diamonds$carat < quantile(diamonds$carat, 0.99)), ]
df <- diamonds[(diamonds$price < quantile(diamonds$price, 0.99) &
diamonds$carat < quantile(diamonds$carat, 0.99)), ]
ggplot(data = df, mapping = aes(x = carat, y = price)) +
geom_point()
diamonds$volume <- diamonds$x * diamonds$y * diamonds$z
ggplot(data = diamonds, mapping = aes(x = volume, y = price)) +
geom_point()
df <- diamonds[(diamonds$volume == 0 & diamonds$volume >= 800), ]
cor(df$volume, df$price)
df <- diamonds[(diamonds$volume == 0 | diamonds$volume >= 800), ]
df <- diamonds[(diamonds$volume != 0 | diamonds$volume < 800), ]
df <- diamonds[(diamonds$volume != 0 & diamonds$volume < 800), ]
cor(df$volume, df$price)
load("C:/Project/ChurnPrediction/development/DT_Model.Rdata")
dt_model$frame$var
# Pre-requisite
library(ggplot2)
data("diamonds")
data("diamonds")
library(ggplot2)
data("diamonds")
data("diamonds")
diamonds
diamonds$volume <- diamonds$x * diamonds$y * diamonds$z
df <- diamonds[(diamonds$volume != 0 & diamonds$volume < 800), ]
ggplot(data = df, mapping = aes(x = volume, y = price)) +
geom_point(alpha = 0.01) +
geom_smooth(method = "lm")
ggplot(data = df, mapping = aes(x = volume, y = price)) +
geom_point(alpha = 0.1) +
geom_smooth(method = "lm")
ggplot(data = df, mapping = aes(x = volume, y = price)) +
geom_point() +
geom_smooth(method = "lm")
suppressMessages(library(ggplot2))
suppressMessages(library(dplyr))
?summarize
diamondsByClarity <- summarise(group_by(diamonds, clarity),
mean_price = mean(price),
median_price = median(price),
min_price = min(price),
max_price = max(price),
n = n())
View(diamondsByClarity)
library(gridExtra)
?grid.arrange
diamonds_mp_by_clarity <- summarise(group_by(diamonds, clarity),
mean_price = mean(price))
diamonds_mp_by_color <- summarise(group_by(diamonds, color),
mean_price = mean(price))
View(diamonds_mp_by_clarity)
View(diamonds_mp_by_color)
p1 <- ggplot(data = diamonds_mp_by_clarity, mapping = aes(x = clarity,
y = mean_price)) +
geom_bar()
p2 <- ggplot(data = diamonds_mp_by_color, mapping = aes(x = color,
y = mean_price)) +
geom_bar()
grid.arrange(p1, p2)
p1 <- ggplot(data = diamonds_mp_by_clarity, mapping = aes(x = clarity,
y = mean_price)) +
geom_bar()
p2 <- ggplot(data = diamonds_mp_by_color, mapping = aes(x = color,
y = mean_price)) +
geom_bar()
grid.arrange(p1, p2, ncol = 2)
p1 <- ggplot(data = diamonds_mp_by_clarity, mapping = aes(x = clarity,
y = mean_price)) +
geom_col()
p2 <- ggplot(data = diamonds_mp_by_color, mapping = aes(x = color,
y = mean_price)) +
geom_col()
grid.arrange(p1, p2, ncol = 2)
View(diamonds_mp_by_clarity)
View(diamonds)
setwd("C:/Project/Udacity/4 ExploreAndSummarizeData/lesson5")
pf <- read.delim('../pseudo_facebook.tsv')
pf$year_joined <- floor(2014 - pf$tenure / 365)
View(pf)
?cut
pf$year_joined.bucket <- cut(pf$year_joined, c(2004, 2009, 2011, 2012))
View(pf)
pf$year_joined.bucket <- cut(pf$year_joined, c(2004, 2009, 2011, 2012, 2014))
ggplot(aes(x = age, y = friend_count),
data = subset(pf, !is.na(year_joined.bucket))) +
geom_line(aes(color = year_joined.bucket), stat = 'summary', fun.y = median)
